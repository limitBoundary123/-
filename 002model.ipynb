{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1ac770",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightgbm import LGBMRegressor\n",
    "import joblib\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# 加载数据\n",
    "file_path = \"D:/ProgrammingLeaning/JupyterLearning/产品订单processed_data/feature_engineering2015-201901_data0622.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "date_column = \"order_date\"  # 日期列\n",
    "    \n",
    "# 转换日期列\n",
    "data[date_column] = pd.to_datetime(data[date_column])\n",
    "    \n",
    "# 去重处理\n",
    "data.drop_duplicates(inplace=True)\n",
    "    \n",
    "# 删除日期列\n",
    "data = data.drop(columns=['order_date'])\n",
    "# 删除 D 列为 1 到 60 的数据\n",
    "data = data[data['D'] > 60]\n",
    "data.to_csv(\"D:/test0626.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a5783b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data, encoder=None, fit_encoder=True):\n",
    "    \n",
    "    \n",
    "    # 转换对象类型列为分类变量\n",
    "    categorical_columns = ['season', 'month_phase']\n",
    "    if fit_encoder:\n",
    "        encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "        encoded = encoder.fit_transform(data[categorical_columns])\n",
    "        encoded_df = pd.DataFrame(encoded, columns=encoder.get_feature_names_out(categorical_columns))\n",
    "        data = pd.concat([data.drop(columns=categorical_columns), encoded_df], axis=1)\n",
    "    else:\n",
    "        encoded = encoder.transform(data[categorical_columns])\n",
    "        encoded_df = pd.DataFrame(encoded, columns=encoder.get_feature_names_out(categorical_columns))\n",
    "        data = pd.concat([data.drop(columns=categorical_columns), encoded_df], axis=1)\n",
    "    print(data.shape)\n",
    "    # 确保 is_holiday 和 is_promo 列为布尔类型\n",
    "    if 'is_holiday' in data.columns:\n",
    "        data['is_holiday'] = data['is_holiday'].astype(bool)\n",
    "    if 'is_promo' in data.columns:\n",
    "        data['is_promo'] = data['is_promo'].astype(bool)\n",
    "    # 删除日期列\n",
    "    print(data.shape)\n",
    "    data = data.drop(columns=['order_date'])\n",
    "    \n",
    "    # 删除 D 列为 1 到 60 的数据\n",
    "    data = data[data['D'] > 60]\n",
    "    print(data.shape)\n",
    "    # 删除不需要的列\n",
    "    columns_to_drop = ['Unnamed: 0', 'item_price', 'sales_chan_name']\n",
    "    \n",
    "    data.drop(columns=columns_to_drop, inplace=True)\n",
    "    print(data.shape)\n",
    "    \n",
    "    # 删除 sales_region_code 为空的数据\n",
    "    data = data.dropna(subset=['sales_region_code'])\n",
    "\n",
    "    print(data.shape)\n",
    "    return data, encoder\n",
    "\n",
    "# 加载数据\n",
    "file_path = \"D:/ProgrammingLeaning/JupyterLearning/产品订单processed_data/feature_engineering2015-201901_data0622.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "date_column = \"order_date\"  # 日期列\n",
    "    \n",
    "# 转换日期列\n",
    "data[date_column] = pd.to_datetime(data[date_column])\n",
    "    \n",
    "# 去重处理\n",
    "data.drop_duplicates(inplace=True)\n",
    "    \n",
    "# 预处理数据并保存编码器\n",
    "processed_data, encoder = preprocess_data(data)\n",
    "print(\"Preprocessing is done!\")\n",
    "    \n",
    "# 保存处理后的数据\n",
    "processed_data.to_csv(\"D:/ProgrammingLeaning/JupyterLearning/产品订单processed_data/test3preprocessed_02_data0626.csv\", index=False)\n",
    "joblib.dump(encoder, \"D:/ProgrammingLeaning/JupyterLearning/产品订单processed_data/test3encoder0626.pkl\")\n",
    "print(\"Processed data and encoder are saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5161f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载预处理后的数据和编码器\n",
    "file_path = \"D:/ProgrammingLeaning/JupyterLearning/产品订单processed_data/test3preprocessed_02_data0626.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "encoder = joblib.load(\"D:/ProgrammingLeaning/JupyterLearning/产品订单processed_data/test3encoder0626.pkl\")\n",
    "\n",
    "\n",
    "# 获取日期范围\n",
    "max_date = data['D'].max()\n",
    "valid_start_date = max_date - 70-140-100\n",
    "test_start_date = max_date - 41\n",
    "\n",
    "# 初始化空的预测结果数据框\n",
    "test = pd.DataFrame()\n",
    "valid = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e33e97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def construct_date(year, month, day):\n",
    "    return pd.to_datetime(dict(year=year, month=month, day=day))\n",
    "\n",
    "def get_date_range(df):\n",
    "    min_date = df['constructed_date'].min()\n",
    "    max_date = df['constructed_date'].max()\n",
    "    return min_date, max_date\n",
    "\n",
    "def main():\n",
    "    # 加载数据\n",
    "    file_path = \"D:/ProgrammingLeaning/JupyterLearning/产品订单processed_data/test3preprocessed_02_data0626.csv\"\n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "    # 构造日期列\n",
    "    data['constructed_date'] = construct_date(data['Year'], data['Month'], data['day'])\n",
    "    \n",
    "    # 获取日期范围\n",
    "    max_date = data['D'].max()\n",
    "    valid_start_date = max_date - 70 - 140 - 100\n",
    "    test_start_date = max_date - 41\n",
    "\n",
    "    # 划分数据集\n",
    "    train_df = data[data['D'] < valid_start_date]\n",
    "    valid_df = data[(data['D'] >= valid_start_date) & (data['D'] < test_start_date)]\n",
    "    test_df = data[data['D'] >= test_start_date]\n",
    "\n",
    "    # 获取各个数据集的日期范围和数据数量\n",
    "    train_min_date, train_max_date = get_date_range(train_df)\n",
    "    valid_min_date, valid_max_date = get_date_range(valid_df)\n",
    "    test_min_date, test_max_date = get_date_range(test_df)\n",
    "    \n",
    "    # 输出训练集信息\n",
    "    print(f\"训练集日期范围: 从{train_min_date.date()}到{train_max_date.date()}\")\n",
    "    print(f\"训练集数据数量: {len(train_df)}条\")\n",
    "    \n",
    "    # 输出验证集信息\n",
    "    print(f\"验证集日期范围: 从{valid_min_date.date()}到{valid_max_date.date()}\")\n",
    "    print(f\"验证集数据数量: {len(valid_df)}条\")\n",
    "    \n",
    "    # 输出测试集信息\n",
    "    print(f\"测试集日期范围: 从{test_min_date.date()}到{test_max_date.date()}\")\n",
    "    print(f\"测试集数据数量: {len(test_df)}条\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6126b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_logloss(model, store):\n",
    "    evals_result = model.evals_result_\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(evals_result['training']['rmse'], label='Train RMSE')\n",
    "    plt.plot(evals_result['valid_1']['rmse'], label='Test RMSE')\n",
    "    plt.title('RMSE Log for Store {}'.format(store))\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('RMSE')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_predictions(y_true, y_pred, title, num_points=500):\n",
    "    y_pred = np.maximum(y_pred, 0)\n",
    "    x_axis = np.linspace(1, len(y_true), len(y_true))\n",
    "    plt.figure(dpi=300, figsize=(28, 12))\n",
    "    plt.plot(x_axis[:num_points], y_true.values[:num_points], color='blue', label='True')\n",
    "    plt.plot(x_axis[:num_points], y_pred[:num_points], color='red', linestyle='--', label='Prediction')\n",
    "    plt.legend(prop={'size': 20})\n",
    "    plt.xlabel('Time', fontsize=20)\n",
    "    plt.ylabel('Order Quantity', fontsize=20)\n",
    "    plt.title(title, fontdict={'family': 'SimSun', 'weight': 'normal', 'size': 20})\n",
    "    plt.tick_params(labelsize=20)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def train_and_evaluate(model, x_train, x_valid, y_train, y_valid, store):\n",
    "    model.fit(x_train, y_train, eval_set=[(x_train, y_train), (x_valid, y_valid)], eval_metric='rmse')\n",
    "    \n",
    "    # 评估训练集性能\n",
    "    y_train_pred = model.predict(x_train)\n",
    "    train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "    train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    train_rmse = np.sqrt(train_mse)\n",
    "    train_mape = np.mean(np.abs((y_train - y_train_pred) / y_train)) * 100\n",
    "\n",
    "    # 评估验证集性能\n",
    "    y_valid_pred = model.predict(x_valid)\n",
    "    valid_mse = mean_squared_error(y_valid, y_valid_pred)\n",
    "    valid_mae = mean_absolute_error(y_valid, y_valid_pred)\n",
    "    valid_r2 = r2_score(y_valid, y_valid_pred)\n",
    "    valid_rmse = np.sqrt(valid_mse)\n",
    "    valid_mape = np.mean(np.abs((y_valid - y_valid_pred) / y_valid)) * 100\n",
    "\n",
    "    # 绘制预测与真实值对比图\n",
    "    plot_predictions(y_valid, y_valid_pred, f'真实值与预测值对比 for Store {store} (测试集)', num_points=500)\n",
    "\n",
    "    return {\n",
    "        \"train\": {\"MSE\": train_mse, \"MAE\": train_mae, \"R2\": train_r2, \"MAPE\": train_mape, \"RMSE\": train_rmse},\n",
    "        \"valid\": {\"MSE\": valid_mse, \"MAE\": valid_mae, \"R2\": valid_r2, \"MAPE\": valid_mape, \"RMSE\": valid_rmse}\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b36659",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 建立每个销售区域的模型\n",
    "states = list(set(data['sales_region_code']))\n",
    "for store in states:\n",
    "    try:\n",
    "        df = data[data['sales_region_code'] == store]\n",
    "        print('Processing sales region:', store)\n",
    "        print('Data length:', len(df))\n",
    "        \n",
    "        # 划分数据\n",
    "        X_train = df[df['D'] < valid_start_date].drop('ord_qty', axis=1)\n",
    "        y_train = df[df['D'] < valid_start_date]['ord_qty']\n",
    "        X_valid = df[(df['D'] >= valid_start_date) & (df['D'] < test_start_date)].drop('ord_qty', axis=1)\n",
    "        y_valid = df[(df['D'] >= valid_start_date) & (df['D'] < test_start_date)]['ord_qty']\n",
    "        X_test = df[df['D'] >= test_start_date].drop('ord_qty', axis=1)\n",
    "\n",
    "        # 训练并验证模型\n",
    "        model = LGBMRegressor(\n",
    "            n_estimators=1000,\n",
    "            learning_rate=0.3,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            max_depth=8,\n",
    "            num_leaves=50,\n",
    "            min_child_weight=300,\n",
    "            verbose=-1\n",
    "        )\n",
    "        print('*****Prediction for sales region: {}*****'.format(store))\n",
    "        evaluation_results = train_and_evaluate(model, X_train, X_valid, y_train, y_valid, store)\n",
    "        print(\"Training set evaluation:\", evaluation_results[\"train\"])\n",
    "        print(\"Validation set evaluation:\", evaluation_results[\"valid\"])\n",
    "\n",
    "        valid_preds = pd.Series(index=X_valid.index, data=model.predict(X_valid))\n",
    "        eval_preds = pd.Series(index=X_test.index, data=model.predict(X_test))\n",
    "        \n",
    "        # 确保所有预测值为非负数\n",
    "        eval_preds = eval_preds.apply(lambda x: max(x, 0))\n",
    "        valid_preds = valid_preds.apply(lambda x: max(x, 0))\n",
    "\n",
    "        # 保存模型\n",
    "        filename = \"D:/ProgrammingLeaning/JupyterLearning/产品订单processed_data/test3model0626_\" + str(store) + \".pkl\"\n",
    "        joblib.dump(model, filename)\n",
    "        plot_logloss(model, store)\n",
    "\n",
    "        # 保存预测结果\n",
    "        test = pd.concat([test, pd.DataFrame({'predicted_ord_qty': eval_preds})])\n",
    "        valid = pd.concat([valid, pd.DataFrame({'predicted_ord_qty': valid_preds})])\n",
    "\n",
    "        del model, X_train, y_train, X_valid, y_valid\n",
    "    except Exception as e:\n",
    "        print(f\"Error for store {store}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298346dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取相应的日期信息并添加到预测结果中\n",
    "test['order_date'] = data.loc[test.index, 'D'].apply(lambda x: (pd.to_datetime('2015-09-01') + pd.to_timedelta(x, unit='D')).date())\n",
    "valid['order_date'] = data.loc[valid.index, 'D'].apply(lambda x: (pd.to_datetime('2015-09-01') + pd.to_timedelta(x, unit='D')).date())\n",
    "\n",
    "# 添加 sales_region_code, item_code, first_cate_code, second_cate_code 信息\n",
    "test[['sales_region_code', 'item_code', 'first_cate_code', 'second_cate_code']] = data.loc[test.index, ['sales_region_code', 'item_code', 'first_cate_code', 'second_cate_code']]\n",
    "valid[['sales_region_code', 'item_code', 'first_cate_code', 'second_cate_code']] = data.loc[valid.index, ['sales_region_code', 'item_code', 'first_cate_code', 'second_cate_code']]\n",
    "\n",
    "# 保存预测结果\n",
    "test.to_csv(\"D:/ProgrammingLeaning/JupyterLearning/产品订单processed_data/test3_0626predicted_2019_data.csv\", index=False)\n",
    "valid.to_csv(\"D:/ProgrammingLeaning/JupyterLearning/产品订单processed_data/test3_0626valid_2019_data.csv\", index=False)\n",
    "print(\"预测结果已保存到文件 predicted_2019_data.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc9ef52",
   "metadata": {},
   "outputs": [],
   "source": [
    "################# 下面四个模型########################################\n",
    "################# RF随机森林、XGBoost、CatBoost、决策树DT\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "import joblib\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def plot_logloss(model, store, model_name):\n",
    "    if hasattr(model, 'evals_result_'):\n",
    "        evals_result = model.evals_result_\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(evals_result['validation_0']['rmse'], label='Train RMSE')\n",
    "        plt.plot(evals_result['validation_1']['rmse'], label='Valid RMSE')\n",
    "        plt.title('RMSE Log for Store {} with {}'.format(store, model_name))\n",
    "        plt.xlabel('Iterations')\n",
    "        plt.ylabel('RMSE')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"No evals_result_ available for {model_name}\")\n",
    "\n",
    "def plot_predictions(y_true, y_pred, title, num_points=500):\n",
    "    y_pred = np.maximum(y_pred, 0)\n",
    "    x_axis = np.linspace(1, len(y_true), len(y_true))\n",
    "    plt.figure(dpi=300, figsize=(28, 12))\n",
    "    plt.plot(x_axis[:num_points], y_true.values[:num_points], color='blue', label='True')\n",
    "    plt.plot(x_axis[:num_points], y_pred[:num_points], color='red', linestyle='--', label='Prediction')\n",
    "    plt.legend(prop={'size': 20})\n",
    "    plt.xlabel('Time', fontsize=20)\n",
    "    plt.ylabel('Order Quantity', fontsize=20)\n",
    "    plt.title(title, fontdict={'family': 'SimSun', 'weight': 'normal', 'size': 20})\n",
    "    plt.tick_params(labelsize=20)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def train_and_evaluate(model, x_train, x_valid, y_train, y_valid, store, model_name):\n",
    "    if model_name in [\"XGBoost\"]:\n",
    "        if x_train.empty or x_valid.empty:\n",
    "            raise ValueError(f\"No samples available for store {store} with {model_name}\")\n",
    "        model.fit(x_train, y_train, eval_set=[(x_valid, y_valid)], verbose=False)\n",
    "    elif model_name in [\"CatBoost\"]:\n",
    "        model.fit(x_train, y_train, eval_set=[(x_valid, y_valid)])\n",
    "    else:\n",
    "        # 处理缺失值\n",
    "        x_train = x_train.fillna(x_train.mean())\n",
    "        x_valid = x_valid.fillna(x_valid.mean())\n",
    "        model.fit(x_train, y_train)\n",
    "    \n",
    "    # 评估训练集性能\n",
    "    y_train_pred = model.predict(x_train)\n",
    "    train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "    train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    train_rmse = np.sqrt(train_mse)\n",
    "    train_mape = np.mean(np.abs((y_train - y_train_pred) / y_train)) * 100\n",
    "\n",
    "    # 评估验证集性能\n",
    "    y_valid_pred = model.predict(x_valid)\n",
    "    valid_mse = mean_squared_error(y_valid, y_valid_pred)\n",
    "    valid_mae = mean_absolute_error(y_valid, y_valid_pred)\n",
    "    valid_r2 = r2_score(y_valid, y_valid_pred)\n",
    "    valid_rmse = np.sqrt(valid_mse)\n",
    "    valid_mape = np.mean(np.abs((y_valid - y_valid_pred) / y_valid)) * 100\n",
    "\n",
    "    # 绘制预测与真实值对比图\n",
    "    plot_predictions(y_valid, y_valid_pred, f'真实值与预测值对比 for Store {store} with {model_name} (测试集)', num_points=500)\n",
    "\n",
    "    return {\n",
    "        \"train\": {\"MSE\": train_mse, \"MAE\": train_mae, \"R2\": train_r2, \"MAPE\": train_mape, \"RMSE\": train_rmse},\n",
    "        \"valid\": {\"MSE\": valid_mse, \"MAE\": valid_mae, \"R2\": valid_r2, \"MAPE\": valid_mape, \"RMSE\": valid_rmse}\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8591aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 划分数据集并训练RandomForest模型\n",
    "for store in states:\n",
    "    try:\n",
    "        df = data[data['sales_region_code'] == store]\n",
    "        print('Processing sales region:', store)\n",
    "        print('Data length:', len(df))\n",
    "        \n",
    "        # 划分数据\n",
    "        X_train = df[df['D'] < valid_start_date].drop('ord_qty', axis=1)\n",
    "        y_train = df[df['D'] < valid_start_date]['ord_qty']\n",
    "        X_valid = df[(df['D'] >= valid_start_date) & (df['D'] < test_start_date)].drop('ord_qty', axis=1)\n",
    "        y_valid = df[(df['D'] >= valid_start_date) & (df['D'] < test_start_date)]['ord_qty']\n",
    "        X_test = df[df['D'] >= test_start_date].drop('ord_qty', axis=1)\n",
    "\n",
    "        # 训练并验证模型\n",
    "        model = RandomForestRegressor(n_estimators=1000, max_depth=10, min_samples_split=2, min_samples_leaf=1, random_state=42, n_jobs=-1)\n",
    "        print(f'*****Prediction for sales region: {store} with RandomForest*****')\n",
    "        evaluation_results = train_and_evaluate(model, X_train, X_valid, y_train, y_valid, store, \"RandomForest\")\n",
    "        print(\"Training set evaluation:\", evaluation_results[\"train\"])\n",
    "        print(\"Validation set evaluation:\", evaluation_results[\"valid\"])\n",
    "\n",
    "        valid_preds = pd.Series(index=X_valid.index, data=model.predict(X_valid))\n",
    "        eval_preds = pd.Series(index=X_test.index, data=model.predict(X_test))\n",
    "        \n",
    "        # 确保所有预测值为非负数\n",
    "        eval_preds = eval_preds.apply(lambda x: max(x, 0))\n",
    "        valid_preds = valid_preds.apply(lambda x: max(x, 0))\n",
    "\n",
    "        # 保存模型\n",
    "        filename = f\"D:/ProgrammingLeaning/JupyterLearning/产品订单processed_data/RandomForest_model_\" + str(store) + \".pkl\"\n",
    "        joblib.dump(model, filename)\n",
    "\n",
    "        # 保存预测结果\n",
    "        test = pd.concat([test, pd.DataFrame({'predicted_ord_qty': eval_preds})])\n",
    "        valid = pd.concat([valid, pd.DataFrame({'predicted_ord_qty': valid_preds})])\n",
    "\n",
    "        del model, X_train, y_train, X_valid, y_valid\n",
    "    except Exception as e:\n",
    "        print(f\"Error for store {store} with RandomForest: {e}\")\n",
    "        continue\n",
    "\n",
    "# 提取相应的日期信息并添加到预测结果中\n",
    "test['order_date'] = data.loc[test.index, 'D'].apply(lambda x: (pd.to_datetime('2015-09-01') + pd.to_timedelta(x, unit='D')).date())\n",
    "valid['order_date'] = data.loc[valid.index, 'D'].apply(lambda x: (pd.to_datetime('2015-09-01') + pd.to_timedelta(x, unit='D')).date())\n",
    "\n",
    "# 添加 sales_region_code, item_code, first_cate_code, second_cate_code 信息\n",
    "test[['sales_region_code', 'item_code', 'first_cate_code', 'second_cate_code']] = data.loc[test.index, ['sales_region_code', 'item_code', 'first_cate_code', 'second_cate_code']]\n",
    "valid[['sales_region_code', 'item_code', 'first_cate_code', 'second_cate_code']] = data.loc[valid.index, ['sales_region_code', 'item_code', 'first_cate_code', 'second_cate_code']]\n",
    "\n",
    "# 保存预测结果\n",
    "test.to_csv(\"D:/ProgrammingLeaning/JupyterLearning/产品订单processed_data/RF_predicted_2019_data.csv\", index=False)\n",
    "valid.to_csv(\"D:/ProgrammingLeaning/JupyterLearning/产品订单processed_data/RF_valid_2019_data.csv\", index=False)\n",
    "print(\"预测结果已保存到文件 predicted_2019_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3b74d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 划分数据集并训练XGBoost模型\n",
    "for store in states:\n",
    "    try:\n",
    "        df = data[data['sales_region_code'] == store]\n",
    "        print('Processing sales region:', store)\n",
    "        print('Data length:', len(df))\n",
    "        \n",
    "        # 划分数据\n",
    "        X_train = df[df['D'] < valid_start_date].drop('ord_qty', axis=1)\n",
    "        y_train = df[df['D'] < valid_start_date]['ord_qty']\n",
    "        X_valid = df[(df['D'] >= valid_start_date) & (df['D'] < test_start_date)].drop('ord_qty', axis=1)\n",
    "        y_valid = df[(df['D'] >= valid_start_date) & (df['D'] < test_start_date)]['ord_qty']\n",
    "        X_test = df[df['D'] >= test_start_date].drop('ord_qty', axis=1)\n",
    "\n",
    "        if X_train.empty or X_valid.empty:\n",
    "            print(f\"No samples available for store {store} with XGBoost\")\n",
    "            continue\n",
    "        \n",
    "        # 训练并验证模型\n",
    "        model = XGBRegressor(n_estimators=1000, learning_rate=0.1, max_depth=6, subsample=0.8, colsample_bytree=0.8, random_state=42, n_jobs=-1, eval_metric='rmse')\n",
    "        print(f'*****Prediction for sales region: {store} with XGBoost*****')\n",
    "        evaluation_results = train_and_evaluate(model, X_train, X_valid, y_train, y_valid, store, \"XGBoost\")\n",
    "        print(\"Training set evaluation:\", evaluation_results[\"train\"])\n",
    "        print(\"Validation set evaluation:\", evaluation_results[\"valid\"])\n",
    "\n",
    "        valid_preds = pd.Series(index=X_valid.index, data=model.predict(X_valid))\n",
    "        eval_preds = pd.Series(index=X_test.index, data=model.predict(X_test))\n",
    "        \n",
    "        # 确保所有预测值为非负数\n",
    "        eval_preds = eval_preds.apply(lambda x: max(x, 0))\n",
    "        valid_preds = valid_preds.apply(lambda x: max(x, 0))\n",
    "\n",
    "        # 保存模型\n",
    "        filename = f\"D:/ProgrammingLeaning/JupyterLearning/产品订单processed_data/XGBoost_model_\" + str(store) + \".pkl\"\n",
    "        joblib.dump(model, filename)\n",
    "\n",
    "        # 绘制损失函数图像\n",
    "        #plot_logloss2(model, store, \"XGBoost\")\n",
    "\n",
    "        # 保存预测结果\n",
    "        test = pd.concat([test, pd.DataFrame({'predicted_ord_qty': eval_preds})])\n",
    "        valid = pd.concat([valid, pd.DataFrame({'predicted_ord_qty': valid_preds})])\n",
    "\n",
    "        del model, X_train, y_train, X_valid, y_valid\n",
    "    except Exception as e:\n",
    "        print(f\"Error for store {store} with XGBoost: {e}\")\n",
    "        continue\n",
    "\n",
    "# 提取相应的日期信息并添加到预测结果中\n",
    "test['order_date'] = data.loc[test.index, 'D'].apply(lambda x: (pd.to_datetime('2015-09-01') + pd.to_timedelta(x, unit='D')).date())\n",
    "valid['order_date'] = data.loc[valid.index, 'D'].apply(lambda x: (pd.to_datetime('2015-09-01') + pd.to_timedelta(x, unit='D')).date())\n",
    "\n",
    "# 添加 sales_region_code, item_code, first_cate_code, second_cate_code 信息\n",
    "test[['sales_region_code', 'item_code', 'first_cate_code', 'second_cate_code']] = data.loc[test.index, ['sales_region_code', 'item_code', 'first_cate_code', 'second_cate_code']]\n",
    "valid[['sales_region_code', 'item_code', 'first_cate_code', 'second_cate_code']] = data.loc[valid.index, ['sales_region_code', 'item_code', 'first_cate_code', 'second_cate_code']]\n",
    "\n",
    "# 保存预测结果\n",
    "test.to_csv(\"D:/ProgrammingLeaning/JupyterLearning/产品订单processed_data/XGBoost_predicted_2019_data.csv\", index=False)\n",
    "valid.to_csv(\"D:/ProgrammingLeaning/JupyterLearning/产品订单processed_data/XGBoost_valid_2019_data.csv\", index=False)\n",
    "print(\"预测结果已保存到文件 predicted_2019_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb79913d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, x_train, x_valid, y_train, y_valid, store, model_name):\n",
    "    if model_name in [\"XGBoost\"]:\n",
    "        if x_train.empty or x_valid.empty:\n",
    "            raise ValueError(f\"No samples available for store {store} with {model_name}\")\n",
    "        model.fit(x_train, y_train, eval_set=[(x_valid, y_valid)], verbose=False)\n",
    "    elif model_name in [\"CatBoost\"]:\n",
    "        if x_train.empty or y_train.empty or x_valid.empty or y_valid.empty:\n",
    "            raise ValueError(f\"No samples available for store {store} with {model_name}\")\n",
    "        model.fit(x_train, y_train, eval_set=(x_valid, y_valid), verbose=False)\n",
    "    else:\n",
    "        # 处理缺失值\n",
    "        x_train = x_train.fillna(x_train.mean())\n",
    "        x_valid = x_valid.fillna(x_valid.mean())\n",
    "        model.fit(x_train, y_train)\n",
    "    \n",
    "    # 评估训练集性能\n",
    "    y_train_pred = model.predict(x_train)\n",
    "    train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "    train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    train_rmse = np.sqrt(train_mse)\n",
    "    train_mape = np.mean(np.abs((y_train - y_train_pred) / y_train)) * 100\n",
    "\n",
    "    # 评估验证集性能\n",
    "    y_valid_pred = model.predict(x_valid)\n",
    "    valid_mse = mean_squared_error(y_valid, y_valid_pred)\n",
    "    valid_mae = mean_absolute_error(y_valid, y_valid_pred)\n",
    "    valid_r2 = r2_score(y_valid, y_valid_pred)\n",
    "    valid_rmse = np.sqrt(valid_mse)\n",
    "    valid_mape = np.mean(np.abs((y_valid - y_valid_pred) / y_valid)) * 100\n",
    "\n",
    "    # 绘制预测与真实值对比图\n",
    "    plot_predictions(y_valid, y_valid_pred, f'真实值与预测值对比 for Store {store} with {model_name} (验证集)', num_points=500)\n",
    "\n",
    "    return {\n",
    "        \"train\": {\"MSE\": train_mse, \"MAE\": train_mae, \"R2\": train_r2, \"MAPE\": train_mape, \"RMSE\": train_rmse},\n",
    "        \"valid\": {\"MSE\": valid_mse, \"MAE\": valid_mae, \"R2\": valid_r2, \"MAPE\": valid_mape, \"RMSE\": valid_rmse}\n",
    "    }\n",
    "\n",
    "\n",
    "# 划分数据集并训练CatBoost模型\n",
    "# 划分数据集并训练CatBoost模型\n",
    "for store in states:\n",
    "    try:\n",
    "        df = data[data['sales_region_code'] == store]\n",
    "        print('Processing sales region:', store)\n",
    "        print('Data length:', len(df))\n",
    "        \n",
    "        # 划分数据\n",
    "        X_train = df[df['D'] < valid_start_date].drop('ord_qty', axis=1)\n",
    "        y_train = df[df['D'] < valid_start_date]['ord_qty']\n",
    "        X_valid = df[(df['D'] >= valid_start_date) & (df['D'] < test_start_date)].drop('ord_qty', axis=1)\n",
    "        y_valid = df[(df['D'] >= valid_start_date) & (df['D'] < test_start_date)]['ord_qty']\n",
    "        X_test = df[df['D'] >= test_start_date].drop('ord_qty', axis=1)\n",
    "        \n",
    "        # 确保数据集不为空\n",
    "        if X_train.empty or y_train.empty or X_valid.empty or y_valid.empty:\n",
    "            print(f\"No samples available for store {store} with CatBoost\")\n",
    "            continue\n",
    "        \n",
    "        # 训练并验证模型\n",
    "        model = CatBoostRegressor(iterations=1000, learning_rate=0.1, depth=6, random_seed=42, verbose=0)\n",
    "        print(f'*****Prediction for sales region: {store} with CatBoost*****')\n",
    "        evaluation_results = train_and_evaluate(model, X_train, X_valid, y_train, y_valid, store, \"CatBoost\")\n",
    "        print(\"Training set evaluation:\", evaluation_results[\"train\"])\n",
    "        print(\"Validation set evaluation:\", evaluation_results[\"valid\"])\n",
    "\n",
    "        valid_preds = pd.Series(index=X_valid.index, data=model.predict(X_valid))\n",
    "        eval_preds = pd.Series(index=X_test.index, data=model.predict(X_test))\n",
    "        \n",
    "        # 确保所有预测值为非负数\n",
    "        eval_preds = eval_preds.apply(lambda x: max(x, 0))\n",
    "        valid_preds = valid_preds.apply(lambda x: max(x, 0))\n",
    "\n",
    "        # 保存模型\n",
    "        filename = f\"D:/ProgrammingLeaning/JupyterLearning/产品订单processed_data/CatBoost_model_\" + str(store) + \".pkl\"\n",
    "        joblib.dump(model, filename)\n",
    "\n",
    "        # 保存预测结果\n",
    "        test = pd.concat([test, pd.DataFrame({'predicted_ord_qty': eval_preds})])\n",
    "        valid = pd.concat([valid, pd.DataFrame({'predicted_ord_qty': valid_preds})])\n",
    "\n",
    "        del model, X_train, y_train, X_valid, y_valid\n",
    "    except Exception as e:\n",
    "        print(f\"Error for store {store} with CatBoost: {e}\")\n",
    "        continue\n",
    "\n",
    "# 提取相应的日期信息并添加到预测结果中\n",
    "test['order_date'] = data.loc[test.index, 'D'].apply(lambda x: (pd.to_datetime('2015-09-01') + pd.to_timedelta(x, unit='D')).date())\n",
    "valid['order_date'] = data.loc[valid.index, 'D'].apply(lambda x: (pd.to_datetime('2015-09-01') + pd.to_timedelta(x, unit='D')).date())\n",
    "\n",
    "# 添加 sales_region_code, item_code, first_cate_code, second_cate_code 信息\n",
    "test[['sales_region_code', 'item_code', 'first_cate_code', 'second_cate_code']] = data.loc[test.index, ['sales_region_code', 'item_code', 'first_cate_code', 'second_cate_code']]\n",
    "valid[['sales_region_code', 'item_code', 'first_cate_code', 'second_cate_code']] = data.loc[valid.index, ['sales_region_code', 'item_code', 'first_cate_code', 'second_cate_code']]\n",
    "\n",
    "# 保存预测结果\n",
    "test.to_csv(\"D:/ProgrammingLeaning/JupyterLearning/产品订单processed_data/Cat_predicted_2019_data.csv\", index=False)\n",
    "valid.to_csv(\"D:/ProgrammingLeaning/JupyterLearning/产品订单processed_data/Cat_valid_2019_data.csv\", index=False)\n",
    "print(\"预测结果已保存到文件 predicted_2019_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c512f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 读取预测数据\n",
    "predicted_data_path = \"D:/ProgrammingLeaning/JupyterLearning/产品订单processed_data/Cat_predicted_2019_data.csv\"\n",
    "predicted_data = pd.read_csv(predicted_data_path)\n",
    "\n",
    "# 筛选出2019年的数据\n",
    "predicted_data['order_date'] = pd.to_datetime(predicted_data['order_date'])\n",
    "predicted_data_2019 = predicted_data[predicted_data['order_date'].dt.year == 2019]\n",
    "\n",
    "# 加载原始数据\n",
    "file_path = \"D:/ProgrammingLeaning/JupyterLearning/order_train1.csv\"\n",
    "original_data = pd.read_csv(file_path)\n",
    "\n",
    "# 获取原始数据中的产品编码\n",
    "original_item_codes = set(original_data['item_code'].unique())\n",
    "\n",
    "# 找出新品（在原始数据中不存在的产品编码）\n",
    "new_items = predicted_data_2019[~predicted_data_2019['item_code'].isin(original_item_codes)]\n",
    "\n",
    "# 统计新品数量\n",
    "new_item_count = new_items['item_code'].nunique()\n",
    "\n",
    "# 用同一销售区域、第一类别和第二类别分组的平均值填充新品的预测需求量\n",
    "fill_count = 0\n",
    "for index, row in new_items.iterrows():\n",
    "    group_mean = predicted_data_2019[(predicted_data_2019['sales_region_code'] == row['sales_region_code']) &\n",
    "                                     (predicted_data_2019['first_cate_code'] == row['first_cate_code']) &\n",
    "                                     \n",
    "                                     (predicted_data_2019['second_cate_code'] == row['second_cate_code'])]['predicted_ord_qty'].mean()\n",
    "    if not pd.isna(group_mean):\n",
    "        predicted_data_2019.at[index, 'predicted_ord_qty'] = group_mean\n",
    "        fill_count += 1\n",
    "\n",
    "# 将填充后的数据保存回文件\n",
    "filled_predicted_data_path = \"D:/ProgrammingLeaning/JupyterLearning/产品订单processed_data/Cat_predicted_2019_data_filled2.csv\"\n",
    "predicted_data_2019.to_csv(filled_predicted_data_path, index=False)\n",
    "print(f\"新品需求量已填充并保存到文件 {filled_predicted_data_path}\")\n",
    "print(f\"共有 {new_item_count} 种新品，新填充了 {fill_count} 条数据\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cac632f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 读取预测数据\n",
    "predicted_data_path =\"D:/ProgrammingLeaning/JupyterLearning/predict_sku1.csv\"\n",
    "predicted_data = pd.read_csv(predicted_data_path)\n",
    "\n",
    "# 筛选出2019年的数据\n",
    "#predicted_data['order_date'] = pd.to_datetime(predicted_data['order_date'])\n",
    "predicted_data_2019 = predicted_data\n",
    "# 加载原始数据\n",
    "file_path = \"D:/ProgrammingLeaning/JupyterLearning/order_train1.csv\"\n",
    "original_data = pd.read_csv(file_path)\n",
    "\n",
    "# 获取原始数据中的产品编码\n",
    "original_item_codes = set(original_data['item_code'].unique())\n",
    "\n",
    "# 找出新品（在原始数据中不存在的产品编码）\n",
    "new_items = predicted_data_2019[~predicted_data_2019['item_code'].isin(original_item_codes)]\n",
    "\n",
    "# 统计新品数量\n",
    "new_item_count = new_items['item_code'].nunique()\n",
    "\n",
    "\n",
    "print(f\"共有 {new_item_count} 种新品\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61287038",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# 划分数据集并训练决策树回归模型\n",
    "for store in states:\n",
    "    try:\n",
    "        df = data[data['sales_region_code'] == store]\n",
    "        print('Processing sales region:', store)\n",
    "        print('Data length:', len(df))\n",
    "        \n",
    "        # 划分数据\n",
    "        X_train = df[df['D'] < valid_start_date].drop('ord_qty', axis=1)\n",
    "        y_train = df[df['D'] < valid_start_date]['ord_qty']\n",
    "        X_valid = df[(df['D'] >= valid_start_date) & (df['D'] < test_start_date)].drop('ord_qty', axis=1)\n",
    "        y_valid = df[(df['D'] >= valid_start_date) & (df['D'] < test_start_date)]['ord_qty']\n",
    "        X_test = df[df['D'] >= test_start_date].drop('ord_qty', axis=1)\n",
    "\n",
    "        if X_train.empty or y_train.empty or X_valid.empty or y_valid.empty:\n",
    "            print(f\"No samples available for store {store} with DecisionTree\")\n",
    "            continue\n",
    "        \n",
    "        # 训练并验证模型\n",
    "        model = DecisionTreeRegressor(max_depth=10, random_state=42)\n",
    "        print(f'*****Prediction for sales region: {store} with DecisionTree*****')\n",
    "        evaluation_results = train_and_evaluate(model, X_train, X_valid, y_train, y_valid, store, \"DecisionTree\")\n",
    "        print(\"Training set evaluation:\", evaluation_results[\"train\"])\n",
    "        print(\"Validation set evaluation:\", evaluation_results[\"valid\"])\n",
    "\n",
    "        valid_preds = pd.Series(index=X_valid.index, data=model.predict(X_valid))\n",
    "        eval_preds = pd.Series(index=X_test.index, data=model.predict(X_test))\n",
    "        \n",
    "        # 确保所有预测值为非负数\n",
    "        eval_preds = eval_preds.apply(lambda x: max(x, 0))\n",
    "        valid_preds = valid_preds.apply(lambda x: max(x, 0))\n",
    "\n",
    "        # 保存模型\n",
    "        filename = f\"D:/ProgrammingLeaning/JupyterLearning/产品订单processed_data/DecisionTree_model_\" + str(store) + \".pkl\"\n",
    "        joblib.dump(model, filename)\n",
    "\n",
    "        # 保存预测结果\n",
    "        test = pd.concat([test, pd.DataFrame({'predicted_ord_qty': eval_preds})])\n",
    "        valid = pd.concat([valid, pd.DataFrame({'predicted_ord_qty': valid_preds})])\n",
    "\n",
    "        del model, X_train, y_train, X_valid, y_valid\n",
    "    except Exception as e:\n",
    "        print(f\"Error for store {store} with DecisionTree: {e}\")\n",
    "        continue\n",
    "\n",
    "# 提取相应的日期信息并添加到预测结果中\n",
    "test['order_date'] = data.loc[test.index, 'D'].apply(lambda x: (pd.to_datetime('2015-09-01') + pd.to_timedelta(x, unit='D')).date())\n",
    "valid['order_date'] = data.loc[valid.index, 'D'].apply(lambda x: (pd.to_datetime('2015-09-01') + pd.to_timedelta(x, unit='D')).date())\n",
    "\n",
    "# 添加 sales_region_code, item_code, first_cate_code, second_cate_code 信息\n",
    "test[['sales_region_code', 'item_code', 'first_cate_code', 'second_cate_code']] = data.loc[test.index, ['sales_region_code', 'item_code', 'first_cate_code', 'second_cate_code']]\n",
    "valid[['sales_region_code', 'item_code', 'first_cate_code', 'second_cate_code']] = data.loc[valid.index, ['sales_region_code', 'item_code', 'first_cate_code', 'second_cate_code']]\n",
    "\n",
    "# 保存预测结果\n",
    "test.to_csv(\"D:/ProgrammingLeaning/JupyterLearning/产品订单processed_data/DecisionTree_predicted_2019_data.csv\", index=False)\n",
    "valid.to_csv(\"D:/ProgrammingLeaning/JupyterLearning/产品订单processed_data/DecisionTree_valid_2019_data.csv\", index=False)\n",
    "print(\"预测结果已保存到文件 predicted_2019_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f57c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, StackingRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "# 定义用于训练和评估的函数\n",
    "def train_and_evaluate_stacking(model, x_train, y_train, x_valid, y_valid, store, cv=5):\n",
    "    # 使用交叉验证生成训练集预测结果\n",
    "    kf = KFold(n_splits=cv)\n",
    "    y_train_pred = cross_val_predict(model, x_train, y_train, cv=kf)\n",
    "    \n",
    "    # 评估训练集性能\n",
    "    train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "    train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    train_rmse = np.sqrt(train_mse)\n",
    "    train_mape = np.mean(np.abs((y_train - y_train_pred) / y_train)) * 100\n",
    "\n",
    "    # 训练模型并生成验证集预测结果\n",
    "    model.fit(x_train, y_train)\n",
    "    y_valid_pred = model.predict(x_valid)\n",
    "    \n",
    "    # 评估验证集性能\n",
    "    valid_mse = mean_squared_error(y_valid, y_valid_pred)\n",
    "    valid_mae = mean_absolute_error(y_valid, y_valid_pred)\n",
    "    valid_r2 = r2_score(y_valid, y_valid_pred)\n",
    "    valid_rmse = np.sqrt(valid_mse)\n",
    "    valid_mape = np.mean(np.abs((y_valid - y_valid_pred) / y_valid)) * 100\n",
    "\n",
    "    # 绘制预测与真实值对比图\n",
    "    plot_predictions(y_valid, y_valid_pred, f'真实值与预测值对比 for Store {store} with Stacking (验证集)', num_points=500)\n",
    "\n",
    "    return {\n",
    "        \"train\": {\"MSE\": train_mse, \"MAE\": train_mae, \"R2\": train_r2, \"MAPE\": train_mape, \"RMSE\": train_rmse},\n",
    "        \"valid\": {\"MSE\": valid_mse, \"MAE\": valid_mae, \"R2\": valid_r2, \"MAPE\": valid_mape, \"RMSE\": valid_rmse}\n",
    "    }\n",
    "\n",
    "def plot_predictions(y_true, y_pred, title, num_points=500):\n",
    "    y_pred = np.maximum(y_pred, 0)\n",
    "    x_axis = np.linspace(1, len(y_true), len(y_true))\n",
    "    plt.figure(dpi=300, figsize=(28, 12))\n",
    "    plt.plot(x_axis[:num_points], y_true.values[:num_points], color='blue', label='True')\n",
    "    plt.plot(x_axis[:num_points], y_pred[:num_points], color='red', linestyle='--', label='Prediction')\n",
    "    plt.legend(prop={'size': 20})\n",
    "    plt.xlabel('Time', fontsize=20)\n",
    "    plt.ylabel('Order Quantity', fontsize=20)\n",
    "    plt.title(title, fontdict={'family': 'SimSun', 'weight': 'normal', 'size': 20})\n",
    "    plt.tick_params(labelsize=20)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# 加载模型\n",
    "lgbm_models = {}\n",
    "xgb_models = {}\n",
    "#rf_models = {}\n",
    "catboost_models = {}\n",
    "dt_models = {}\n",
    "\n",
    "for store in states:\n",
    "    try:\n",
    "        lgbm_models[store] = joblib.load(f\"D:/ProgrammingLeaning/JupyterLearning/产品订单processed_data/LGBM_model_{store}.pkl\")\n",
    "        xgb_models[store] = joblib.load(f\"D:/ProgrammingLeaning/JupyterLearning/产品订单processed_data/XGBoost_model_{store}.pkl\")\n",
    "        #rf_models[store] = joblib.load(f\"D:/ProgrammingLeaning/JupyterLearning/产品订单processed_data/RandomForest_model_{store}.pkl\")\n",
    "        catboost_models[store] = joblib.load(f\"D:/ProgrammingLeaning/JupyterLearning/产品订单processed_data/CatBoost_model_{store}.pkl\")\n",
    "        dt_models[store] = joblib.load(f\"D:/ProgrammingLeaning/JupyterLearning/产品订单processed_data/DecisionTree_model_{store}.pkl\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model for store {store}: {e}\")\n",
    "\n",
    "# 获取日期范围\n",
    "max_date = data['D'].max()\n",
    "valid_start_date = max_date - 70 - 140 - 100\n",
    "test_start_date = max_date - 41\n",
    "\n",
    "# 初始化空的预测结果数据框\n",
    "test = pd.DataFrame()\n",
    "valid = pd.DataFrame()\n",
    "\n",
    "# 训练 Stacking 模型\n",
    "for store in states:\n",
    "    try:\n",
    "        df = data[data['sales_region_code'] == store]\n",
    "        print('Processing sales region:', store)\n",
    "        print('Data length:', len(df))\n",
    "        \n",
    "        # 划分数据\n",
    "        X_train = df[df['D'] < valid_start_date].drop('ord_qty', axis=1)\n",
    "        y_train = df[df['D'] < valid_start_date]['ord_qty']\n",
    "        X_valid = df[(df['D'] >= valid_start_date) & (df['D'] < test_start_date)].drop('ord_qty', axis=1)\n",
    "        y_valid = df[(df['D'] >= valid_start_date) & (df['D'] < test_start_date)]['ord_qty']\n",
    "        X_test = df[df['D'] >= test_start_date].drop('ord_qty', axis=1)\n",
    "\n",
    "        if X_train.empty or y_train.empty or X_valid.empty or y_valid.empty:\n",
    "            print(f\"No samples available for store {store} with Stacking\")\n",
    "            continue\n",
    "        \n",
    "        # 创建基础模型列表\n",
    "        estimators = [\n",
    "            ('lgbm', lgbm_models[store]),\n",
    "            ('xgb', xgb_models[store]),\n",
    "            #('rf', rf_models[store]),\n",
    "            ('catboost', catboost_models[store]),\n",
    "            ('dt', dt_models[store])\n",
    "        ]\n",
    "\n",
    "        # 创建 StackingRegressor\n",
    "        stacking_model = StackingRegressor(estimators=estimators, final_estimator=RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "\n",
    "        # 训练并评估 Stacking 模型\n",
    "        evaluation_results = train_and_evaluate_stacking(stacking_model, X_train, y_train, X_valid, y_valid, store)\n",
    "        print(f\"Training set evaluation for store {store} with Stacking: {evaluation_results['train']}\")\n",
    "        print(f\"Validation set evaluation for store {store} with Stacking: {evaluation_results['valid']}\")\n",
    "\n",
    "        valid_preds = pd.Series(index=X_valid.index, data=stacking_model.predict(X_valid))\n",
    "        eval_preds = pd.Series(index=X_test.index, data=stacking_model.predict(X_test))\n",
    "        \n",
    "        # 确保所有预测值为非负数\n",
    "        eval_preds = eval_preds.apply(lambda x: max(x, 0))\n",
    "        valid_preds = valid_preds.apply(lambda x: max(x, 0))\n",
    "\n",
    "        # 保存 Stacking 模型\n",
    "        filename = f\"D:/ProgrammingLeaning/JupyterLearning/产品订单processed_data/Stacking_model_\" + str(store) + \".pkl\"\n",
    "        joblib.dump(stacking_model, filename)\n",
    "\n",
    "        # 保存预测结果\n",
    "        test = pd.concat([test, pd.DataFrame({'predicted_ord_qty': eval_preds})])\n",
    "        valid = pd.concat([valid, pd.DataFrame({'predicted_ord_qty': valid_preds})])\n",
    "\n",
    "        del stacking_model, X_train, y_train, X_valid, y_valid\n",
    "    except Exception as e:\n",
    "        print(f\"Error for store {store} with Stacking: {e}\")\n",
    "        continue\n",
    "# 提取相应的日期信息并添加到预测结果中\n",
    "test['order_date'] = data.loc[test.index, 'D'].apply(lambda x: (pd.to_datetime('2015-09-01') + pd.to_timedelta(x, unit='D')).date())\n",
    "valid['order_date'] = data.loc[valid.index, 'D'].apply(lambda x: (pd.to_datetime('2015-09-01') + pd.to_timedelta(x, unit='D')).date())\n",
    "\n",
    "# 添加 sales_region_code, item_code, first_cate_code, second_cate_code 信息\n",
    "test[['sales_region_code', 'item_code', 'first_cate_code', 'second_cate_code']] = data.loc[test.index, ['sales_region_code', 'item_code', 'first_cate_code', 'second_cate_code']]\n",
    "valid[['sales_region_code', 'item_code', 'first_cate_code', 'second_cate_code']] = data.loc[valid.index, ['sales_region_code', 'item_code', 'first_cate_code', 'second_cate_code']]\n",
    "test.drop_duplicates(inplace=True)\n",
    "# 保存预测结果\n",
    "test.to_csv(\"D:/ProgrammingLeaning/JupyterLearning/产品订单processed_data/Stacking_predicted_2019_data.csv\", index=False)\n",
    "valid.to_csv(\"D:/ProgrammingLeaning/JupyterLearning/产品订单processed_data/Stacking_valid_2019_data.csv\", index=False)\n",
    "print(\"预测结果已保存到文件 Stacking_predicted_2019_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98099b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 读取预测数据\n",
    "predicted_data_path = \"D:/ProgrammingLeaning/JupyterLearning/产品订单processed_data/Stacking_predicted_2019_data.csv\"\n",
    "predicted_data = pd.read_csv(predicted_data_path)\n",
    "\n",
    "# 筛选出2019年的数据\n",
    "predicted_data['order_date'] = pd.to_datetime(predicted_data['order_date'])\n",
    "predicted_data_2019 = predicted_data[predicted_data['order_date'].dt.year == 2019]\n",
    "\n",
    "# 加载原始数据\n",
    "file_path = \"D:/ProgrammingLeaning/JupyterLearning/order_train1.csv\"\n",
    "original_data = pd.read_csv(file_path)\n",
    "\n",
    "# 获取原始数据中的产品编码\n",
    "original_item_codes = set(original_data['item_code'].unique())\n",
    "\n",
    "# 找出新品（在原始数据中不存在的产品编码）\n",
    "new_items = predicted_data_2019[~predicted_data_2019['item_code'].isin(original_item_codes)]\n",
    "\n",
    "# 统计新品数量\n",
    "new_item_count = new_items['item_code'].nunique()\n",
    "\n",
    "# 用同一销售区域、第一类别和第二类别分组的平均值填充新品的预测需求量\n",
    "fill_count = 0\n",
    "for index, row in new_items.iterrows():\n",
    "    group_mean = predicted_data_2019[(predicted_data_2019['sales_region_code'] == row['sales_region_code']) &\n",
    "                                     (predicted_data_2019['first_cate_code'] == row['first_cate_code']) &\n",
    "                                     \n",
    "                                     (predicted_data_2019['second_cate_code'] == row['second_cate_code'])]['predicted_ord_qty'].mean()\n",
    "    if not pd.isna(group_mean):\n",
    "        predicted_data_2019.at[index, 'predicted_ord_qty'] = group_mean\n",
    "        fill_count += 1\n",
    "\n",
    "# 将填充后的数据保存回文件\n",
    "filled_predicted_data_path = \"D:/ProgrammingLeaning/JupyterLearning/产品订单processed_data/Stacking_predicted_2019_data_filled.csv\"\n",
    "predicted_data_2019.to_csv(filled_predicted_data_path, index=False)\n",
    "print(f\"新品需求量已填充并保存到文件 {filled_predicted_data_path}\")\n",
    "print(f\"共有 {new_item_count} 种新品，新填充了 {fill_count} 条数据\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceec4dd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# 配置字体\n",
    "plt.rcParams['font.family'] = 'SimHei'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 加载模型\n",
    "lgbm_model = joblib.load(\"D:/ProgrammingLeaning/JupyterLearning/产品订单processed_data/LGBM_model_105.0.pkl\")\n",
    "xgb_model = joblib.load(\"D:/ProgrammingLeaning/JupyterLearning/产品订单processed_data/XGBoost_model_105.0.pkl\")\n",
    "dt_model = joblib.load(\"D:/ProgrammingLeaning/JupyterLearning/产品订单processed_data/DecisionTree_model_105.0.pkl\")\n",
    "catboost_model = joblib.load(\"D:/ProgrammingLeaning/JupyterLearning/产品订单processed_data/CatBoost_model_105.0.pkl\")\n",
    "stacking_model = joblib.load(\"D:/ProgrammingLeaning/JupyterLearning/产品订单processed_data/Stacking_model_105.0.pkl\")\n",
    "\n",
    "# 提取特征重要性\n",
    "lgbm_importance = lgbm_model.feature_importances_\n",
    "xgb_importance = xgb_model.feature_importances_\n",
    "dt_importance = dt_model.feature_importances_\n",
    "catboost_importance = catboost_model.get_feature_importance()\n",
    "features = data.columns.drop('ord_qty')\n",
    "\n",
    "# 定义绘制特征重要性图的函数\n",
    "def plot_feature_importance(importances, features, model_name):\n",
    "    if len(importances) == len(features):\n",
    "        mask = features != 'demand_trend'\n",
    "        importances = importances[mask]\n",
    "        features = features[mask]\n",
    "    indices = np.argsort(importances)[::-1][:10]\n",
    "    top_importances = importances[indices]\n",
    "    top_features = [features[i] for i in indices]\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.title(f\"{model_name} 特征重要性图\", fontsize=16)\n",
    "    bars = plt.bar(range(len(top_importances)), top_importances, align=\"center\", color=plt.cm.tab20.colors)\n",
    "    plt.xticks(range(len(top_importances)), top_features, rotation=90, fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 绘制特征重要性图\n",
    "plot_feature_importance(lgbm_importance, features, \"LightGBM\")\n",
    "plot_feature_importance(xgb_importance, features, \"XGBoost\")\n",
    "plot_feature_importance(dt_importance, features, \"Decision Tree\")\n",
    "plot_feature_importance(catboost_importance, features, \"CatBoost\")\n",
    "\n",
    "# 对于Stacking模型，使用final_estimator的特征重要性\n",
    "stacking_importance = stacking_model.final_estimator_.feature_importances_\n",
    "\n",
    "# 确保特征名称与stacking_importance的维度匹配\n",
    "stacking_features = features[:len(stacking_importance)]\n",
    "\n",
    "plot_feature_importance(stacking_importance, stacking_features, \"Stacking\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b858dc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取最终输出的表格\n",
    "predicted_data_path = \"D:/ProgrammingLeaning/JupyterLearning/产品订单processed_data/Stacking_predicted_2019_data_filled.csv\"\n",
    "data = pd.read_csv(predicted_data_path)\n",
    "\n",
    "# 生成新的表格结构\n",
    "new_data = data.groupby(['sales_region_code', 'item_code', 'first_cate_code', 'second_cate_code'])['predicted_ord_qty'].sum().reset_index()\n",
    "new_data.rename(columns={'predicted_ord_qty': '2019年1月预测需求量'}, inplace=True)\n",
    "\n",
    "# 保存新的表格\n",
    "new_data_path = \"D:/ProgrammingLeaning/JupyterLearning/产品订单processed_data/Stacking_predicted_2019_data_Monthsummary.csv\"\n",
    "new_data.to_csv(new_data_path, index=False)\n",
    "\n",
    "print(\"新的表格已保存到文件 Stacking_predicted_2019_data_Monthsummary.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
